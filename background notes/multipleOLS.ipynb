{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "# Background Note \n",
    "\n",
    "# Ordinary Least Squares: Multiple OLS\n",
    "\n",
    "# By Albert S. Kyle\n",
    "\n",
    "$\\def \\sm {} \\renewcommand{\\sm}{ {\\scriptstyle{\\text{*}}}}$ \n",
    "$\\def \\mm {} \\renewcommand{\\mm}{{\\scriptsize @}}$\n",
    "$\\def \\E {} \\renewcommand{\\E}{\\mathrm{E}}$\n",
    "$\\def \\e {} \\renewcommand{\\e}{\\mathrm{e}}$\n",
    "$\\def \\drm {} \\renewcommand{\\drm}{\\mathrm{\\, d}}$\n",
    "$\\def \\var {} \\renewcommand{\\var}{\\mathrm{var}}$\n",
    "$\\def \\cov {} \\renewcommand{\\cov}{\\mathrm{cov}}$\n",
    "$\\def \\corr {} \\renewcommand{\\corr}{\\mathrm{corr}}$\n",
    "$\\def \\stdev {} \\renewcommand{\\stdev}{\\mathrm{stdev}}$\n",
    "$\\def \\t {} \\renewcommand{\\t}{^{\\mathsf{T}}}$\n",
    "$\\def \\comma {} \\renewcommand{\\comma}{\\, , \\,}$\n",
    "$\\def \\vec {} \\renewcommand{\\vec}[1]{\\mathbf{#1}}$\n",
    "$\\def \\skew {} \\renewcommand{\\skew}{\\mathrm{skew}}$\n",
    "$\\def \\kurt {} \\renewcommand{\\kurt}{\\mathrm{kurt}}$\n",
    "$\\def \\prob {} \\renewcommand{\\prob}{\\textrm{prob}}$\n",
    "$\\def \\midx {} \\renewcommand{\\midx}{\\, \\mid \\,}$\n",
    "$\\def \\argmin {} \\renewcommand{\\argmin}[1]{\\underset{#1}{\\mathrm{argmin}}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version 3.12.8 | packaged by conda-forge | (main, Dec  5 2024, 14:06:27) [MSC v.1942 64 bit (AMD64)]\n",
      "Pandas version 2.2.3\n",
      "NumPy version 1.26.4\n",
      "SciPy version 1.15.1\n",
      "matplotlib version 3.10.0\n",
      "Timestamp: 2025-0902-1626\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import datetime\n",
    "import timeit\n",
    "import math\n",
    "import statistics\n",
    "import nbconvert\n",
    "\n",
    "print('Python version ' + sys.version)\n",
    "print('Pandas version ' + pd.__version__)\n",
    "print('NumPy version ' + np.__version__)\n",
    "print('SciPy version ' + scipy.__version__)\n",
    "print('matplotlib version ' + matplotlib.__version__)\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime('%Y-%m%d-%H%M')\n",
    "print(\"Timestamp:\", timestamp)\n",
    "tstart = timeit.default_timer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This note considers **ordinary least squares** (**OLS**) with an arbitrary number of independent variables.\n",
    "\n",
    "OLS is a mathematical procedure which minimizes the **sum of squared errors** (or **mean squared error**) to approximate a **dependent variable** (left-hand side variable) as a linear function of one or more **independent variables** (right-had side variables).\n",
    "\n",
    "OLS can be used as a statistical method for estimating a **linear regression model**. A regression model imposes a statistical structure on the data.\n",
    "\n",
    "In this note, we ignore any probabilistic statistical structure. Instead, we focus on OLS as a methodology for describing or approximating data as a linear function of other data.\n",
    "\n",
    "This reduces the problem to one involving **matrix algebra** but not **statistics**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problem\n",
    "\n",
    "Let $\\vec{y} = (\\vec{y}[0], \\ldots, \\vec{y}[N-1])$ be a vector of values for a **dependent variable**. Let $\\vec{x}_0$, $\\ldots$, $\\vec{x}_{M-1}$ be $M$ vectors $\\vec{x}_m = (\\vec{x}_m[0], \\ldots, \\vec{x}_m[N-1])$ of **independent variables**.  We would like to approximate or describe the vector $\\vec{y}$ as a linear function of the explanatory variables $\\vec{x_0}$, $\\ldots$, $\\vec{x_{M-1}}$:\n",
    "\n",
    "\\begin{equation}\n",
    "y[n] \\approx \\sum_{m=0}^{M-1} b_m \\sm \\vec{x}_m[n], \\qquad n=0, \\ldots, N-1 .\n",
    "\\end{equation}\n",
    "\n",
    "If the linear function has a constant term, we can think of one of the vectors $\\vec{x}_m$, typically $\\vec{x}_0$, as being a vector of ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Fitting a polynomial\n",
    "\n",
    "Consider the problem of fitting a polynomial of degree $M-1$ to a given scalar-to-scalar function $f(t)$ defined over an interval $[t_{\\text{min}}, t_{\\text{max}}]$. For illustrative purposes, we choose the function $f(t)$ as `np.exp` and the interval as $[-1,+1]$.\n",
    "\n",
    "We will use OLS to fit the polynomial $p(t) := \\sum_{m=0}^{M-1} b_m \\sm t^{m}$ to a sorted list of sample points $\\vec{t} := ( \\vec{t}[0], \\vec{t}[1], \\ldots, \\vec{t}[N-1])$ satisfying $t_{\\text{min}} \\le \\vec{t}[0] \\le \\vec{t}[0] \\le \\ldots \\le \\vec{t}[N-1] \\le t_{\\text{max}}$.\n",
    "\n",
    "Define a set of points to be fit, $\\vec{y} := f(\\vec{t})$, where $f(\\vec{t})$ for a vector argument $\\vec{t}$ denotes the **element-by-element** values of the function (i.e., $\\vec{y}[n] = f(\\vec{t}[n])$). Define a matrix of explanatory variables $\\vec{X}$ as an $N \\times M$ matrix with $\\vec{X}[n, m] = \\vec{t}[n]^m$, $m=0,\\ldots,M-1$. The $m\\!$ th column of $\\vec{X}$ represents the elements of $\\vec{t}$ raised to the $m\\!$ th power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python advice for novices:\n",
    "\n",
    "1. Set the problem up so that numerical calculations can be performed using the Python packages Numpy and Scipy, which are optimized for numerical calculations and have specialized functions already defined for efficiently accomplishing taskes like we are attempting to perform.  \n",
    "\n",
    "2. It is likely to be inefficient to write slow Python loops of the form `for n in range(N): [...do something numerical...]`, if loopping over a large number of elements.\n",
    "\n",
    "3. To avoid Python loops, it is helpful if the function $f$ is defined so that it returns a scalar result for a scalar argument and returns an element-by-element array when the argument is an array. Numpy calls such functions **universal functions** (`ufunc`). Many basic Numpy functions, such as `np.exp` and `np.log`, are `ufunc`s. When you define functions using Numpy, they will often automatically be universal functions. Such functions will also attempt to **broadcast** elements and will be **vectorizd** so that looping is fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a function `f_poly_fit` to accomplish our task. Here is a start, which generates the data to define $\\vec{y}$ and $\\vec{X}$. We will add code for OLS later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fun=<ufunc 'exp'>\n",
      "t0=0.0\n",
      "t1=1.0\n",
      "y=array([1.        , 1.10517092, 1.22140276, 1.34985881, 1.4918247 ,\n",
      "       1.64872127, 1.8221188 , 2.01375271, 2.22554093, 2.45960311,\n",
      "       2.71828183])\n",
      "x=array([[1.   , 0.   , 0.   , 0.   ],\n",
      "       [1.   , 0.1  , 0.01 , 0.001],\n",
      "       [1.   , 0.2  , 0.04 , 0.008],\n",
      "       [1.   , 0.3  , 0.09 , 0.027],\n",
      "       [1.   , 0.4  , 0.16 , 0.064],\n",
      "       [1.   , 0.5  , 0.25 , 0.125],\n",
      "       [1.   , 0.6  , 0.36 , 0.216],\n",
      "       [1.   , 0.7  , 0.49 , 0.343],\n",
      "       [1.   , 0.8  , 0.64 , 0.512],\n",
      "       [1.   , 0.9  , 0.81 , 0.729],\n",
      "       [1.   , 1.   , 1.   , 1.   ]])\n",
      "t.dtype=dtype('float64'), x.dtype=dtype('float64'), y.dtype=dtype('float64')\n"
     ]
    }
   ],
   "source": [
    "def f_poly_fit_OLS(fun, t0=0.00, t1=1.00, nobs=11, degree=3):\n",
    "    N = nobs\n",
    "    M = degree + 1\n",
    "    t = np.linspace(start=t0, stop=t1, num=N, endpoint=True, retstep=False, dtype=np.float64)\n",
    "    y = fun(t)\n",
    "    x = t.reshape(N,1)**np.array(range(M)).reshape(1, M)\n",
    "    \n",
    "    print(f\"{fun=}\\n{t0=}\\n{t1=}\\n{y=}\\n{x=}\")\n",
    "    print(f\"{t.dtype=}, {x.dtype=}, {y.dtype=}\")\n",
    "    \n",
    "    #TODO: Add rest of code to fit data with OLS\n",
    "\n",
    "f_poly_fit_OLS(fun=np.exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 (very easy)\n",
    "\n",
    "Answer each question with one simple sentence:\n",
    "\n",
    "1. What does the functions `reshape(N,1)` and `reshape(1,M)` actually do?  What is the purpose of using the `reshape` function in this problem? Instead of `reshape(N,1)`, verify that you obtain the same result with the \"shortcut\" `reshape(-1,1)`. Which is the safer and more transparent coding strategy, using or avoiding $-1$?\n",
    "\n",
    "2. Why is the `dtype` of `t` equal to `np.float64`? How would change the `dtype` to `np.float32`? What happens if the `dtype` argument is omitted? \n",
    "\n",
    "Hint: Use the Numpy documentation to answer these questions if trial and error does not make it obvious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The objective function\n",
    "\n",
    "**OLS** minimizes the **sum of squared errors**, which is defined by the objective function\n",
    "\n",
    "\\begin{equation}\n",
    "f_{obj}(b_0, \\ldots, b_M) := \\sum_{n=0}^{N-1} \\left( y_n - b_1 \\sm x_{0, n} - \\ldots - b_{M-1} \\sm x_{M-1, n} \\right)^2 .\n",
    "\\end{equation}\n",
    "\n",
    "To express this in a more compact manner, stack the $M$ column vectors $\\vec{x}_m$ horizontally into an $N \\times M$ matrix $\\vec{X}$, where the $m\\!$ th column of $\\vec{X}$ is the vector $\\vec{x}_m$.  Also, stack the linear coefficients into an $M \\times 1$ vector $\\vec{b} = (b_0, \\ldots, b_M)$. The matrix-vector product $\\vec{X} \\mm \\vec{b}$ is a vector of length $N$ which approximates $\\vec{y}$. The approximation errors, called **residuals**, are given compactly in matrix notation by $\\vec{y} - \\vec{X} \\mm \\vec{b} $.\n",
    "\n",
    "We can now express the objective function as\n",
    "\n",
    "\\begin{equation}\n",
    "f_{obj}(\\vec{b}; \\vec{y}, \\vec{X}) :=  \\left( \\vec{y} - \\vec{X} \\mm \\vec{b} \\right) \\t \\mm  \\left( \\vec{y} - \\vec{X} \\mm \\vec{b} \\right).\n",
    "\\end{equation}\n",
    "\n",
    "Here, in the definition of the objective function $f_{obj}(\\vec{b}; \\vec{y}, \\vec{X})$, the $\\vec{b}$ before the semi-colon means that $f_{obj}$ is a function of the vector of parameters $\\vec{b}$. The $\\vec{y}$ and $\\vec{X}$ after the semi-colon remind us that the function depends on the data $\\vec{y}$ and $\\vec{X}$ as inputs.\n",
    "\n",
    "The mathematical problem for OLS is to find the value of the $M$ OLS coefficients $\\vec{b}$ which minimizes the objective function:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\hat{\\vec{b}} &:= \\argmin{\\vec{b}} \\left[ f_{obj}(\\vec{b}; \\vec{y}, \\vec{X}) \\right] \\\\\n",
    "&= \\argmin{\\vec{b}} \\left[ \\left( \\vec{y} - \\vec{X} \\mm \\vec{b} \\right) \\t  \\mm \\left( \\vec{y} - \\vec{X} \\mm \\vec{b} \\right) \\right].\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "Obviously, the least-squares minimizing vector $\\hat{\\vec{b}}$ is a function of $\\vec{X}$ and $\\vec{y}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mathematical Solution: First-order conditions and Normal Equations\n",
    "\n",
    "The **gradient** of the objective function is defined as its derivative with respect to the vector $\\vec{b}$. This derivative is a vector of length $M$ (the number of parameters, which is the number of elements in $\\vec{b}$), whose $m\\!$ th component is the partial derivative of the objective function with respect to $m\\!$ th component of $\\vec{b}$. This **gradient vector** is sometimes written as a row vector and sometimes as a column vector. Here we make it a columan vector and express the derivative in matrix notation as\n",
    "\n",
    "\\begin{equation}\n",
    "f'_{obj} \\left( \\vec{b}; \\vec{y}, \\vec{X} \\right) = -2 \\sm  \\vec{X} \\t \\mm \\left( \\vec{y} - \\vec{X} \\mm \\vec{b} \\right) .\n",
    "\\end{equation}\n",
    "\n",
    "At the minimum value of the objective function, the gradient vector is equal to the $M \\times 1$ zero vector, denoted $\\vec{0}_M$ or simply $\\vec{0}$ when $M$ can be inferred from the context. If the gradient is not zero, the objective function can be improved locally by changing $\\vec{b}$ by a small amount in the direction opposite the gradient. If the gradient is zero, small changes in the gradient do not affect the objective function much. This intuition gives us the first-order conditions, which can be written in vector notation as\n",
    "\n",
    "\\begin{equation}\n",
    "-2 \\sm  \\vec{X} \\t \\mm \\left( \\vec{y} - \\vec{X} \\mm \\hat{\\vec{b}} \\right) = \\vec{0} .\n",
    "\\end{equation}\n",
    "\n",
    "The first-order conditions are equivalent to the **normal equations**\n",
    "\n",
    "\\begin{equation}\n",
    "\\vec{X} \\t \\mm \\vec{X} \\mm \\hat{\\vec{b}} = \\vec{X} \\t \\mm \\vec{y} .\n",
    "\\end{equation}\n",
    "\n",
    "The normal equations are a system of linear matrix equations of the form $\\vec{A} \\mm \\vec{b} = \\vec{c}$, where $\\vec{A} = \\vec{X} \\t \\mm \\vec{X}$ is a known positive semi-definite $M \\times M$ matrix, $\\vec{c} = \\vec{X} \\t \\mm \\vec{y}$ is a known $M \\times 1$ vector, and $\\hat{\\vec{b}}$ is an unknown vector of OLS coefficient estimates to be solved for. \n",
    "\n",
    "The second derivative of the objective function is an $M \\times M$ **hessian** matrix given by\n",
    "\n",
    "\\begin{equation}\n",
    "f''_{obj} \\left( \\vec{b}; \\vec{y}, \\vec{X} \\right) = 2 \\sm  \\vec{X} \\t \\mm \\vec{X} .\n",
    "\\end{equation}\n",
    "\n",
    "This matrix is **positive semi-definite** since it is the **transpose product** of a matrix with itself. Therefore, the first-order conditions actually define a minimum to the objective function and not a maximum or **saddle point**. (Note: For arbitrary functions, the first-order conditions do not always define a global minimum if the hessian is negative semi-definite; an example is the function $f(x) = x^3$, which does not have a minimum at $x=0$. For quadratic functions, the first-order conditions do define a global minimum when the hession is positive semidefinite. The global minimum is unique if the hessian is negative definite.) \n",
    "\n",
    "Any solution $\\hat{\\vec{b}}$ to the normal equations gives us OLS coefficients which minimize the sum of squared errors.\n",
    "\n",
    "If the matrix $\\vec{X}$ has full rank $M$ (assuming $M < N$, i.e., more observations that variables), then $\\vec{X} \\t \\vec{X}$ is **invertible**, and the solution will be unique. If $\\vec{X}$ has rank less than $M$, $\\vec{X}$ has **multicollinearity**, $\\vec{X} \\t \\vec{X}$ is **singular**, and the solution will not be unique. One way to deal with this is to drop just enough linearly dependent columns of $\\vec{X}$ to make the the reduced matrix have full rank. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Understand the linear algebra (easy)\n",
    "\n",
    "Make sure that you understand the linear algebra in the previous cell.  It permeates everything in statistics and machine learning.\n",
    "\n",
    "1. How can you infer from the context of the equation $-2 \\sm  \\vec{X} \\t \\mm \\left( \\vec{y} - \\vec{X} \\mm \\hat{\\vec{b}} \\right) = \\vec{0}$ that $\\vec{0}$ has length $M$?\n",
    "\n",
    "2. If you are calculating $\\vec{X} \\t \\mm \\vec{X} \\mm \\vec{b}$, is it better to calculate $(\\vec{X} \\t  \\mm\\vec{X}) \\mm \\vec{b}$ or $\\vec{X} \\t \\mm (\\vec{X} \\mm \\vec{b})$?\n",
    "\n",
    "3. Provide a one-line proof that the product of a matrix with its own transpose, such as $\\vec{X} \\t \\mm \\vec{X}$, is positive semi-definite.\n",
    "\n",
    "4. Why do the first- and second-order conditions guarantee a global minimum and not a global maximum, local minimum, or something else?\n",
    "\n",
    "5. Based on the assumptions so far, why is the global minimum not necessarily unique?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Implementing OLS using Python\n",
    "\n",
    "There are many ways to calculate the OLS coefficients $\\hat{\\vec{b}}$ using Python packages.  Let's calculate a solution first, then examine how the solution is obtained afterwards.\n",
    "\n",
    "An obvious Numpy solution uses the least-squares function `np.linalg.lstsq(...)`. This function returns a 4-tuple. The desired OLS coefficients are the first element in the tuple.\n",
    "\n",
    "Using `np.linagl.lstsq(...)`, we can redefine the function `f_poly_fit_OLS` so that it calculates the OLS coefficients as well as other information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t.shape=(100,)\n",
      "y.shape=(100,)\n",
      "x.shape=(100, 6)\n",
      "bhat.shape=(6,)\n",
      "yhat.shape=(100,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f_poly_fit_OLS(fun, t0=0.00, t1=1.00, nobs=101, degree=3, bplot=True):\n",
    "    N = nobs\n",
    "    M = degree + 1\n",
    "    t = np.linspace(start=t0, stop=t1, num=N, endpoint=True, retstep=False, dtype=np.float64)\n",
    "    y = fun(t)\n",
    "    x = t.reshape(N, 1)**np.array(range(M)).reshape(1, M)\n",
    "    \n",
    "    print(f\"{t.shape=}\\n{y.shape=}\\n{x.shape=}\")\n",
    "    #print(f\"{f=}\\n{t0=}\\n{t1=}\\n{y=}\\n{x=}\")\n",
    "    #print(f\"{t.dtype=}, {x.dtype=}, {y.dtype=}\")\n",
    "    \n",
    "    bhat, sse, rank, singular_values = np.linalg.lstsq(x, y, rcond=None)\n",
    "    yhat = x @ bhat\n",
    "    residuals = y - yhat\n",
    "    \n",
    "    print(f\"{bhat.shape=}\\n{yhat.shape=}\")\n",
    "    #print(f\"{bhat=}\\n{yhat=}\")\n",
    "\n",
    "    if bplot == True:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=[10,6])\n",
    "        ax[0].set_title(\"y, yhat vs. t\")\n",
    "        ax[0].set_xlabel(\"t\")\n",
    "        ax[0].set_ylabel(\"y, yhat\")\n",
    "        ax[0].plot(t, y, 'r-', ms=4.00, lw=1.00, label= None)\n",
    "        ax[0].plot(t, yhat, 'bo', ms=2.00, lw=0.10, label= None)\n",
    "        ax[1].set_title(\"residuals vs. t\")\n",
    "        ax[1].set_xlabel(\"t\")\n",
    "        ax[1].set_ylabel(\"residuals\")\n",
    "        ax[1].plot(t, residuals, 'ro-', ms=4.00, lw=0.50, label= None)\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "f_poly_fit_OLS(fun=np.exp, nobs=100, degree=5, bplot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Proof without gradients and hessians\n",
    "\n",
    "One way to show that the normal equations (or first-order conditions) characterize the solution, without using gradients and hessians, is to change a proposed solution $\\hat{\\vec{b}}$ by some arbitrary amount $\\Delta \\vec{b}$, then recalculate the objective function:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "f_{obj} \\left( \\vec{b}; \\vec{y}, \\vec{X} \\right) &=  \\left( \\vec{y} - \\vec{X} \\mm (\\vec{b} + \\Delta \\vec{b}) \\right) \\t \\mm \\left( \\vec{y} - \\vec{X} \\mm (\\vec{b} + \\Delta \\vec{b}) \\right) \\\\\n",
    "&=  \\left( \\vec{y} - \\vec{X} \\mm \\vec{b} \\right) \\t \\mm \\left( \\vec{y} - \\vec{X} \\mm \\vec{b} \\right) - 2 \\sm \\left( \\vec{y} - \\vec{X} \\mm \\vec{b} \\right) \\t \\mm \\left( \\vec{X} \\mm \\Delta \\vec{b} \\right) + \\left( \\vec{X} \\mm \\Delta \\vec{b} \\right) \\t \\mm \\left( \\vec{X} \\mm \\Delta \\vec{b} \\right) .\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "Now the second term $- 2 \\sm \\left( \\vec{y} - \\vec{X} \\mm \\vec{b} \\right) \\t \\mm \\left( \\vec{X} \\mm \\Delta \\vec{b} \\right) $ is the inner product of the gradient and $\\Delta \\vec{b}$. \n",
    "\n",
    "Suppose that the first-order conditions (or normal equations) are satisfied. Then the gradient is a vector which is exactly a vector of zeros, so its inner product with $\\Delta \\vec{b}$ is exactly zero.  This gives us\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "f_{obj} \\left( \\hat{\\vec{b}}; \\vec{y}, \\vec{X} \\right) &=   \\left( \\vec{y} - \\vec{X} \\mm \\hat{\\vec{b}} \\right) \\t \\mm \\left( \\vec{y} - \\vec{X} \\mm \\hat{\\vec{b}} \\right) \n",
    "+ \\left( \\vec{X} \\mm \\Delta \\vec{b} \\right) \\t \\mm \\left( \\vec{X} \\mm \\Delta \\vec{b} \\right) .\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "Here, the first term $ \\left( \\vec{y} - \\vec{X} \\mm \\hat{\\vec{b}} \\right) \\t \\mm \\left( \\vec{y} - \\vec{X} \\mm \\hat{\\vec{b}} \\right)$ is the value of the minimized objective function, which is equal to the minimized sum of squared errors.  The last term $\\left( \\vec{X} \\mm \\Delta \\vec{b} \\right) \\t \\mm \\left( \\vec{X} \\mm \\Delta \\vec{b} \\right)$ is the inner product of a vector $\\vec{X} \\mm \\Delta \\vec{b}$ with itself and is therefore non-negative. Therefore, if the first-order conditions hold, any change $\\Delta \\vec{b}$ cannot make the sum of squared errors smaller.\n",
    "\n",
    "Now suppose that the proposed solution $\\vec{b}$ is such that the first-order conditions do not hold. This means that the vector $-2 \\sm \\left( \\vec{y} - \\vec{X} \\mm \\vec{b} \\right) \\t \\mm \\vec{X}$ multiplying $\\Delta \\vec{b}$ in the second term, $-2 \\sm \\left( \\vec{y} - \\vec{X} \\mm \\vec{b} \\right) \\t \\mm \\left( \\vec{X} \\mm \\Delta \\vec{b} \\right)$, is not a vector of zeros because the normal equations do not hold. We can make the objective function smaller, therefore contradicting the hypothesis that $\\vec{b}$ minimizes the objective function, if we can find a value for the vectore $\\Delta \\vec{b}$ such that the second term, $-2 \\sm \\left( \\vec{y} - \\vec{X} \\mm \\vec{b} \\right) \\t \\mm \\left( \\vec{X} \\mm \\Delta \\vec{b} \\right)$, is negative and has an absolute value greater than the third term, $\\left( \\vec{X} \\mm \\Delta \\vec{b} \\right) \\t \\mm (\\vec{X} \\mm \\Delta \\vec{b})$. To do this choose $\\Delta \\vec{b} := \\epsilon \\sm \\vec{X}  \\t \\mm \\left( \\vec{y} - \\vec{X} \\mm \\vec{b} \\right)$ for some very small positive scalar value $\\epsilon$. This makes the second term minus-2 times the inner product of a nonzero vector with itself, which must be negative.  The second term dominates the third term because the second term is proportional to $\\epsilon$, the third term is proportional to $\\epsilon^2$, and $\\epsilon$ can be very small.\n",
    "\n",
    "\n",
    "This kind of argument is seen frequently in mathematics, statistics, machine learning, and finance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of the OLS solution\n",
    "\n",
    "The **residuals** $\\vec{y} - \\vec{X} \\mm \\hat{\\vec{b}}$ are the errors in the OLS approximation. \n",
    "\n",
    "Two vectors are **orthogonal** if their inner product is zero. This also means their **sample covariance** is zero and their **sample correlation** is zero. \n",
    "\n",
    "The OLS solution has some important properties:\n",
    "\n",
    "The first-order condition $\\vec{X} \\t \\mm \\left( \\vec{y} - \\vec{X} \\mm \\hat{\\vec{b}} \\right) = \\vec{0}$ says that the **residuals** $\\vec{y} - \\vec{X} \\mm \\hat{\\vec{b}}$ are a vector which is orthogonal to each of the columns of $\\vec{X}$. This, of course, implies that the residuals $\\vec{y} - \\vec{X} \\mm \\hat{\\vec{b}}$ are orthogonal to the predicted values $\\vec{X} \\mm \\hat{\\vec{b}}$.\n",
    "\n",
    "If there is a constant term, then one of the columns of $\\vec{X}$ is a column of constants, which are set to one without loss of generality. The residuals $\\vec{y} - \\vec{X} \\mm \\hat{\\vec{b}}$ must be orthogonal to this vector of ones, often denoted with a bold number 1 as $\\vec{1}$. The inner product $\\left( \\vec{y} - \\vec{X} \\mm \\hat{\\vec{b}} \\right) \\t \\mm \\vec{1} = 0$ implies that the average value of the residuals is zero.\n",
    "\n",
    "The **root mean squared error** $\\text{RMSE}$ is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{RMSE} := \\sqrt{ (\\vec{y} - \\vec{X} \\mm \\hat{\\vec{b}}) \\t \\mm (\\vec{y} - \\vec{X} \\mm \\hat{\\vec{b}})}.\n",
    "\\end{equation}\n",
    "\n",
    "The **R-squared** $r^2$ is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "r^2 := \\frac{ \\left( \\vec{y} - \\vec{X} \\mm \\hat{\\vec{b}} \\right) \\t \\mm \\left( \\vec{y} - \\vec{X} \\mm \\hat{\\vec{b}} \\right) }{ \\left( \\vec{y} - \\bar{\\vec{y}} \\right) \\t \\mm \\left( \\vec{y} - \\bar{\\vec{y}} \\right) }.\n",
    "\\end{equation}\n",
    "\n",
    "Notice that the mean of $\\vec{y}$ is subtracted from $\\vec{y}$ itself in the denominator defining $r^2$. This means that the $r^2$ is to be interpreted as the fraction of the **variance** of $\\vec{y}$ explained by $\\vec{X}$. \n",
    "\n",
    "Defining $r^2$ this way has the effect of possibly making the value of $r^2$ negative if a constant term is not included in the OLS approximation. This issue frequently comes up in practice because constant terms are not always used in OLS approximations.\n",
    "\n",
    "An alternative way of defining the $r^2$ is to not subtract the mean in the denominator:\n",
    "\n",
    "\\begin{equation}\n",
    "r^2 := \\frac{ \\left( \\vec{y} - \\vec{X} \\mm \\hat{\\vec{b}} \\right) \\t \\mm \\left( \\vec{y} - \\vec{X} \\mm \\hat{\\vec{b}} \\right) }{ \\vec{y} \\t \\mm \\vec{y} }.\n",
    "\\end{equation}\n",
    "\n",
    "Using this alternative definition makes the interpretation of $r^2$ as the percentage of the **second moment** (not **variance**) explained by the OLS approximation. This alternative definition of $r^2$ guarantees the inequalities $ 0 \\le r^2 \\le 1$, but the $r^2$ can be made close to one by adding a large constant to $\\vec{y}$ in an OLS approximation with a constant term.  \n",
    "\n",
    "This alternative definition is appropriate when the mean of $\\vec{y}$ is close to zero, and there is no constant term in the OLS approximation.\n",
    "\n",
    "In finance applications, the alternative definition is sometimes used when predicting returns, since returns often have a mean close to zero and including a constant term in the OLS approximation is not necessarily appropriate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric Interpretation of OLS\n",
    "\n",
    "Geometrically, the normal equations can be interpreted to say that the error-minimizing vector $\\vec{y} - \\vec{X} \\t \\mm \\hat{\\vec{b}}$, defined by the OLS coefficients $\\hat{\\vec{b}}$, is **orthogonal** (perpendicular) to every vector of the form $\\vec{X} \\mm \\vec{b}$ for arbitrary $\\vec{b}$. For example, if $M = 2$, the space of all vectors $\\vec{X} \\mm \\vec{b}$ can be interpreted to define a \"plane\" in some space of dimension $N$. The normal equations capture the geometric intuition that the shortest distance (root mean-squared error minimizing vector) is obtained by dropping a perpendicular line to the plane defined by $\\vec{X}$. The perpendicular line segment from the point to the plane is the error vector $\\vec{y} - \\vec{X} \\t \\mm \\hat{\\vec{b}}$, and the point in the plane that the line hits is the best estimate $\\vec{X} \\mm \\hat{\\vec{b}}$. \n",
    "\n",
    "The result that a unique error-minimizing vector $\\vec{y} - \\vec{X} \\t \\mm \\hat{\\vec{b}}$ is characterized by being orthogonal to every vector $\\vec{X} \\mm \\vec{b}$ for arbitrary $\\vec{b}$ is an example of what is informally called the **projection theorem**.  Mathematically, the projection theorem can be formalized to make this intuition precise. The formal definition requires a definition of an an **inner product** (which defines orthogonality as an inner product equal to zero) and a **norm** (which measures length or distance). OLS uses the conventional **Euclidean** definitions with the **inner product** defined by $\\vec{x} \\t \\mm \\vec{y} := \\sum_{n=1}^{N} x_n \\sm y_n$  and the **norm** defined by $\\Vert \\vec{x} \\Vert := \\sqrt{ \\vec{x} \\t \\mm \\vec{x} }$. Other definitions are possible. \n",
    "\n",
    "When applied in an infinite dimensional setting (e.g., generalizing our polynomial example to infinite power series expansions), it is called the **Hilbert projection theorem**.\n",
    "\n",
    "When the projection theorem is applied to random variables with zero means, we can interpret inner product as **covariance** and norm as **standard deviation**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection Operators\n",
    "\n",
    "The OLS coefficients define a function mapping a vector $\\vec{y}$ into the optimal estimate $\\vec{X} \\mm \\hat{\\vec{b}}$. Using $\\hat{\\vec{b}} = \\left( \\vec{X} \\t \\mm \\vec{X} \\right)^{-1} \\mm \\left( \\vec{X} \\t \\mm \\vec{y} \\right)$, this function can be defined as\n",
    "\n",
    "\\begin{equation}\n",
    "P \\left( \\vec{y}; \\vec{X} \\right) := \\vec{X} \\mm \\left( \\vec{X} \\t \\mm \\vec{X} \\right)^{-1} \\mm \\vec{X} \\t \\mm \\vec{y}.\n",
    "\\end{equation}\n",
    "\n",
    "The mapping $P( \\vec{y} )$, which maps vectors into vectors, is called a **projection operator** because applying it twice gives the same result as applying it once: $P \\left( P \\left( \\vec{y} \\right) \\right) = P \\left( \\vec{y} \\right) $. The projection operator $P$ is defined by the matrix $\\vec{X} \\mm \\left( \\vec{X} \\t \\mm \\vec{X} \\right)^{-1} \\mm \\vec{X}$. A matrix $\\vec{M}$ is said to be **idempotent** if $\\hat{M} \\mm \\hat{M} = \\hat{M}$. It is easy to verify that $\\vec{X} \\mm \\left( \\vec{X} \\t \\mm \\vec{X} \\right)^{-1} \\mm \\vec{X} \\t$ is an idempotent matrix.  Any idempotent matrix defines a projection operator. \n",
    "\n",
    "The geometric intuition captured by projection operators and idempotent matrices is that the projection of a vector onto a plane is the vector itself when the vector is already in the plane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity\n",
    "\n",
    "The sample correlation coefficient between two vectors $\\hat{x}$ and $\\hat{y}$ is defined by \n",
    "\n",
    "\\begin{equation}\n",
    "r_{x y} = \\frac{ \\left( \\vec{x} - \\bar{\\vec{x}} \\right) \\t \\mm \\left( \\vec{y} - \\bar{\\vec{y}} \\right) }\n",
    "{ \\sqrt{\\left( \\vec{x} - \\bar{\\vec{x}} \\right) \\t \\mm \\left( \\vec{x} - \\bar{\\vec{x}} \\right)} \n",
    "\\sm  \\sqrt{\\left( \\vec{y} - \\bar{\\vec{y}} \\right) \\t \\mm \\left( \\vec{y} - \\bar{\\vec{y}} \\right)} } .\n",
    "\\end{equation}\n",
    "\n",
    "**Cosine similarity** between two vectors is defined by \n",
    "\n",
    "\\begin{equation}\n",
    "S_c(x y) = \\frac{ \\vec{x} \\t \\mm \\vec{y} }{ \\sqrt{ \\vec{x} \\t \\mm \\vec{x} } \n",
    "\\sm  \\sqrt{\\vec{y} \\t \\mm \\vec{y} } } .\n",
    "\\end{equation}\n",
    "\n",
    "Obviously, cosine similarity is equal to the sample correlation coefficient when the two vectors have means of zero.\n",
    "\n",
    "Cosine similarity has the geometric interpretation as the cosine of the angle between two vectors. If the vectors are uncorrelated, this angle is $\\pi /2$ (90 degrees), which defines orthogonality. If the vectors have a correlation of $+1$, the angle is zero. If the correlation is $-1$, the angle is $\\pi$ (180 degrees).\n",
    "\n",
    "If the vectors are first standardized by subtracting their means and dividing by their standard deviations, then both sample correlation and cosine similarity of the demeaned vectors and rescaled vectors correspond to the inner product:\n",
    "\n",
    "\\begin{equation}\n",
    "r_{x y} = C_x \\left( \\vec{x} - \\bar{\\vec{x}} \\comma \\vec{y} - \\bar{\\vec{y}} \\right) = \\vec{z}_x \\t \\mm \\vec{z}_y , \n",
    "\\qquad \\text{where} \\qquad \n",
    "\\vec{z}_x = \\frac{ \\vec{x} - \\bar{\\vec{x}} }{ \\sqrt{ (\\vec{x} - \\bar{\\vec{x}}) \\t \\mm ( \\vec{x} - \\bar{\\vec{x}})}},\n",
    "\\qquad\n",
    "\\vec{z}_y = \\frac{ \\vec{y} - \\bar{\\vec{y}} }{ \\sqrt{ (\\vec{y} - \\bar{\\vec{y}}) \\t \\mm ( \\vec{y} - \\bar{\\vec{y}})}}.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving the normal equations with matrix inverse: not recommended\n",
    "\n",
    "The most obvious way to solve the normal equations, \n",
    "\n",
    "\\begin{equation}\n",
    "\\vec{X} \\t \\mm \\vec{X} \\mm \\hat{\\vec{b}} = \\vec{X} \\t \\mm \\vec{y} ,\n",
    "\\end{equation}\n",
    "\n",
    "for $\\hat{\\vec{b}}$ is to premultiply both sides of the equations by the inverse of the **gram matrix** $\\vec{X} \\t \\mm \\vec{X}$ to obtain the solution\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\vec{b}} = \\left( \\vec{X} \\t \\mm \\vec{X} \\right)^{-1} \\mm \\left( \\vec{X} \\t \\mm \\vec{y} \\right) .\n",
    "\\end{equation}\n",
    "\n",
    "Numerically, this is usually *not the best way to solve the normal equations* due to issues of existence, accuracy, and computational cost:\n",
    "\n",
    "1. If the matrix $\\vec{X}$ does not have full rank, the inverse of $\\vec{X} \\t \\mm \\vec{X}$ is not defined.\n",
    "\n",
    "2. More generally, **multicollinearity** is a term used to describe the case where the columns of $\\vec{X}$ are either not linearly independent or almost not linearly independent in the sense that some column is highly correlated with a linear combination of other columns.  This presents numerical challenges for calculating a matrix inverse.  It is possible that the matrix is theoretically nonsingular, but a numerical inverse calculation fails because the matrix is almost singular.  It is also possible that a matrix is theoretically singular, but a numerical inverse obtains an answer because rounding error appears to make it nonsingular. More generally, the inverse of a matrix may be numerically inaccurate because the inverse is a discontinuous function of the matrix elements for values where the matrix is not invertible. Calculating the inverse of $\\vec{X} \\t \\mm \\vec{X}$ first requires performing the matrix multiplication of $\\vec{X}$ by its own transpose. Multiplying a matrix by its transpose tends to magnify errors.\n",
    "\n",
    "3. Calculating the inverse is computationally expensive. Multiplying $\\vec{X}$ by its own transpose is computationally expensive since approximately $\\tfrac{1}{2} \\sm M^2 \\sm N$ matrix multiplications must be performed ($M^2 \\times N$ if the matrix were not symmetric). It is then computationally expensive to calulate the inverse of the resulting matrix. For large $M$ and $N$, this can computational expense can be important.\n",
    "\n",
    "To summarize, computing the matrix inverse may be less robust, more computationally intensive, and less accurate than alternatives.\n",
    "\n",
    "Therefore, it is recommended to *not use a matrix inverse unless there is a good reason to do so*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving the normal equations with matrix decompositions of $\\vec{X}$\n",
    "\n",
    "The normal equations define a system of linear equations, which is typically solved using **matrix decompositions**. \n",
    "\n",
    "It is usually better to apply a matrix decomposition to the matrix $\\vec{X}$ itself, not to the **gram matrix** $\\vec{X} \\t \\mm \\vec{X}$. There are two reasons for this:\n",
    "\n",
    "1. Calculating $\\vec{X} \\t \\vec{X}$ is computationally costly. As mentioed above, if $\\vec{X}$ is $N \\times M$, the calculation of $\\vec{X} \\t \\mm \\vec{X}$ uses about $\\frac{1}{2} \\sm M^2 \\sm N$ multiplies and a similar number of adds.\n",
    "\n",
    "2. Matrix decompositions of $\\vec{X} \\t \\mm \\vec{X}$ are less accurate than matrix decompositions of $\\vec{X}$. Intuitively, this occurs because the **condition number** of $\\vec{X} \\t \\mm \\vec{X}$ is the square of the condition number of $\\vec{X}$.\n",
    "\n",
    "Therefore, we will first consider decompositions of $\\vec{X}$, not $\\vec{X} \\t \\mm \\vec{X}$.\n",
    "\n",
    "Here are two types of matrix decompositions frequently used to solve the normal equations:\n",
    "\n",
    "1. **Singular value decomposition**: Every matrix $\\vec{X}$ has a **singular value decomposition** of the form  $\\vec{X} = \\vec{U} \\mm \\pmb{\\Sigma} \\mm \\vec{V} \\t$, where $\\vec{U}$ and $\\vec{V}$ have **orthonormal columns** (i.e., $\\vec{U} \\t \\mm \\vec{U}$ and $\\vec{V} \\t \\mm \\vec{V}$ are **identity matrices**), and all of the elements of $\\pmb{\\Sigma}$ are zero except for those on the diagonal, which are nonnegative. There are different versions of the singular value decomposition in which the matrix $\\pmb{\\Sigma}$ has different sizes $N \\times M$, $M \\times M$, or $r \\times r$, where $r$ is the rank of $\\vec{X}$.  When $\\pmb{\\Sigma}$ has $M$ columns, the $M$ diagonal elements of $\\pmb{\\Sigma}$, denoted $\\sigma_1$, $\\ldots$, $\\sigma_M$, are called the **singular values** of $\\vec{X}$. The **condition number** of $\\vec{X}$ is the ratio of the largest singular value to the smallest singular value. The condition number may be infinite, in which case $r < M$ (i.e., the columns of $\\vec{X}$ are not linearly independent).  If $\\pmb{\\Sigma}$ is $M \\times M$ and invertible, then $\\left( \\vec{X} \\t \\mm \\vec{X} \\right)^{-1} = \\vec{U} \\mm \\pmb{\\Sigma}^{-2} \\mm \\vec{U} \\t$, and the solution to the normal equations is $\\hat{\\vec{b}} = \\vec{V} \\mm \\pmb{\\Sigma}^{-1} \\mm \\vec{U} \\t \\mm \\vec{y}$. Define the **pseudoinverse** (**Moore-Penrose inverse**) $\\pmb{\\Sigma}^+$ of $\\pmb{\\Sigma}$ as the matrix obtained by changing nonzero elements (which are all on the diagonal) to their scalar reciprocals, then taking a transpose if $\\pmb{\\Sigma}$ is not diagonal, leaving all zero elements unchanged. If $\\pmb{\\Sigma}$ is square and invertible, the inverse and the pseudoinverse are the same. The **pseudoinverse** of the matrix $\\vec{X}$ is $\\vec{X}^+ := \\vec{V} \\mm \\pmb{\\Sigma}^{+} \\mm \\vec{U} \\t$. If $\\vec{X}$ is square and invertible, then the pseudoinverse is the same as the inverse: $\\vec{X}^+ = \\vec{X}^{-1}$ For any matrix $\\vec{X}$, the solution to the normal equations is $\\hat{\\vec{b}} = \\vec{X}^+  \\mm \\vec{y}$. If $\\vec{X}$ is not full rank, the solution $\\hat{\\vec{b}}$ to the normal equations is not unique, and the pseudoinverse is the solution which minimizes $\\vec{\\hat{b}} \\t \\mm \\vec{\\hat{b}}$. Computationally, the singular value decomposition is slower than the QR decomposition, but it is more accurate and fails less often.  In numerical calculations, singular values which are theoretically zero are often calculated to be small positive numbers; singular values which are theoretically small and nonzero often introduce significant numerical error into calculations because their reciprocal shows up in the calculation of the inverse.  To deal with these numerical issues, the numerical pseudoinverse calculation treats singular values which are very small as if they were zero, then sets the reciprocal of these zeros to zero (as in the Moore-Penrose inverse); this reduces the numerical error in the pseudoinverse associated with taking the inverse of small numbers calculated with their own significant numerical error.\n",
    "\n",
    "2. **QR decomposition**: The **QR decomposition** decomposes any matrix, in this case $\\vec{X}$, into the product of two matrices, $\\vec{X} = \\vec{Q} \\mm \\vec{R}$, where the columns of $\\vec{Q}$ are orthonormal and $\\vec{R}$ is an upper triangular. The solution to the normal equations $\\vec{X} \\t \\mm \\vec{X} \\mm \\hat{\\vec{b}} = \\vec{X} \\t \\mm \\vec{y}$ is the same as the solution to $\\vec{R} \\mm \\hat{\\vec{b}} = \\vec{Q} \\t \\mm (\\vec{X} \\t \\mm \\vec{y})$. This equation is easily solved by backsubstitution since $R$ is triangular. \n",
    "\n",
    "**Multicollinearity** (defined as columns of $\\vec{X}$ being collinear or almost collinear, so that $\\vec{X}$ has less-than-full rank) is a frequent problem for OLS in practice. Sometimes this is due to explanatory variables being highly correlated; other times it is due to mistakes, such as inadvertently including the same explanatory variable twice. Singular value decomposition diagnoses multicollinearity better than other methods. Except for very large problems, computers nowadays are so fast that singular value decomposition takes only a few seconds or less. Except in situations where OLS regressions involve huge amounts of data and computation time is a big factor, singular value decomposition is the recommended computational approach for solving OLS problems.\n",
    "\n",
    "To calculate OLS coefficients using SVD with Python, use `b, residuals, rank, s = np.linalg.lstsq(X, y, rcond=-1)`.\n",
    "\n",
    "Interestingly, while Python uses singular value decomposition as the default least squares algorithm, MatLab has historically used QR decomposition as the default algorithm. I do not know why. Here is my guess: MatLab has been around for a long time. A long time ago,computation time was more important than it is now. Therefore QR decomposition was chosen over SVD to save computation time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving the normal equations with matrix decompositions when $\\vec{X} \\t \\mm \\vec{X}$ has already been calculated\n",
    "\n",
    "Sometimes the matrix $A := \\vec{X} \\t \\mm \\vec{X}$ has already been calculated. Then solving the normal equations is equivalent to solving the system of linear equations $\\vec{A} \\vec{z} =\\vec{v}$ for $\\vec{z}$, where $\\vec{v} := \\vec{X} \\t \\mm \\vec{y}$ and $\\vec{z} := \\vec{b}$.\n",
    "\n",
    "If $\\vec{A}$ is known to be positive definite (not just positive semidefinite), then **Cholesky decomposition** is a fast, stable, accurate algorithm for solving the normal equations.  For a given invertible matrix $\\vec{A}$, the Cholesky decomposition $\\vec{A}$ as $\\vec{A} = \\vec{C} \\t \\mm \\vec{C}$, where $\\vec{C}$ is a lower triangular matrix. Using $C$, the normal equations $\\vec{C} \\t \\mm \\vec{C} = \\vec{X} \\mm \\vec{y}$ can be solved efficiently (one element at a time) in two steps using **backsubstitution**.  If $\\vec{X}$ is singular, the Cholesky decomposition will theoretically fail. If the matrix $\\vec{A}$ is almost singular, Cholesky can theoretically be inaccurate and may fail if the matrix is **numerically singular**. \n",
    "\n",
    "An **LU decomposition** can be used to try to solve an arbitrary system of linear equations, even when the matrix $\\vec{A}$ is not symmetric.  This is not an efficient way to sove the normal equations because the normal equations define a linear system with a special structure: The matrix $\\vec{X} \\t \\mm \\vec{X}$ is (square) symmetric positive definite. This allows more specialized algorithms to be used. Cholesky decomposition is similar to a **LU decomposition**, except that it refines the algorithm to take into account the fact that the gram matrix $\\vec{A} = \\vec{X} \\t \\mm \\vec{X}$ is positive definite (and symmetric) when $\\vec{X}$ has full rank. This makes it twice as fast as LU decomposition, more stable, and more accurate.\n",
    "\n",
    "With Python, the Cholesky decomposition is implemented with  `z = np.linalg.solve(A, v, assume_a='pos')`. The function `np.linalg.solve` is used to solve systems of linear equations, and the option `assuma_a='pos'` tells the function to use a Cholesky decomposition (which will fail if `A` is not positive definite). A good algorithm for testing whether a matrix is positive definite is to try a Cholesky decomposition and see whether it fails or not. If `A` is invertible but not positive definite and not symmetric, the Python function ``z = np.linalg.solve(A, v, assume_a='gen')` will use an LU decomposition.  If the matrix `A` is symmetric, then `z = np.linalg.solve(A, v, assume_a='sym')` will use a version of LU decomposition modified for symmetric matrices.\n",
    "\n",
    "If $\\vec{A}$ is singular or near singular, then Cholesky decomposition may fail, but singular value decomposition or QR decomposition can be applied to the matrix $\\vec{A}$ rather than $\\vec{X}$.  I recommend SVD because it is frequently useful in such situations to understand why the matrix $\\vec{A}$ is singular, and SVD diagnoses this better than QR decomposition.\n",
    "\n",
    "As an approximation, Cholesky decomposition is twice as fast as LU decomposition, LU decomposition is twice as fast as QR decomposition, and QR decomposition is a several times faster than singular value decomposition.\n",
    "\n",
    "The QR decomposition is slower than the Cholesky decomposition, but it fails less often and is more accurate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Moderately difficult but time-consuming.\n",
    "\n",
    "(Instead of working out all of the details, you may want to think about how you would answer the questions, jot down your thoughts quickly, then study the solution to see one way to come up with answers.)\n",
    "\n",
    "The function `np.linalg.lstsq(...)` implements OLS using a singular value decomposition. The function returns the OLS coefficients, the sum of squared errors (value of the objective function), the rank of the matrix $\\vec{X}$, and the vector of $M$ singular values where $M$ is the number of columns of $\\vec{X}.$\n",
    "\n",
    "1. Modify the function `f_poly_fit_OLS(...)` so that it returns a dictionary with the following information: \n",
    "\n",
    "* `fun` : the name of the function being approximated\n",
    "* `interval` : the internal over which the function is approximated (as a tuple)\n",
    "* `nobs` : the number of function values $N$ used to approximate the function (integer)\n",
    "* `degree` : the degree of the approximating polynomial $M-1$ (integer)\n",
    "* `sse` : the sum of squared errors (scalar)\n",
    "* `rank` : the rank of $X$ (integer)\n",
    "* `condition_number` : the condition number of $X$ (scalar)\n",
    "* `rmse` : the root mean squared error (scalar)\n",
    "* `r` : the correlation coefficient (scalar)\n",
    "* `r2` : the R-squared of the OLS calculation (scalar)\n",
    "* `one_minus_r2` : one minus the R-squared (scalar)\n",
    "* `bhat` : the $M$ vector of OLS coefficients (`np.array` of shape `(M+1,)`)\n",
    "* `singular_values` : the $M$ vector of singular values of the matrix $X$ (`np.array` of shape `(M+1,)`)\n",
    "* `yhat` : the approximated values of $y$ (`np.array` of shape `(N,)`)\n",
    "* `residuals` : the $N$ vector of residuals (`np.array` of shape `(N,)`)\n",
    "* `X` : the $N \\times M+1$ matrix of polynomial values (`np.array` of shape `(N, M+1)`)\n",
    "* `y` : the $N$ vector of function values (`np.array` of shape `(N,)`)\n",
    "* `t` : the $N$ vector of points in $\\vec{t}$ \n",
    "* `fig` : an optional figure with two axes, a left-axis with `y` plotted as lines and `yhat` plotted as dots and a right-axis with residuals plotted against `t`\n",
    "\n",
    "2. Print the returned dictionary, with a plot, for the case `fun=np.exp`, `t0=-1.0, t1=1.0`, `nobs=501`, `degree=6`, except when the object to be printed is an array with more than 100 elements, print only its shape.\n",
    "\n",
    "3. Discuss the advantages and disadvantages of returning results of functions as dictionaries rather than tuples.\n",
    "\n",
    "4.  For a specific example, verify that: \n",
    "* The R-squared is the square of the correlation coefficient.\n",
    "* The residuals are orthogonal to every column of the matrix $\\vec{X}$. \n",
    "\n",
    "5. Think of $\\vec{X}$ and  $\\vec{y}$ as a **learning** (\"in sample\") dataset with 501 points. Create a **test** (\"out of sample\") dataset by choosing points $t_{\\text{test}}$ as 1000 randomly chosen points on the \\emph{same} interval $[0, 1]$. Compare the root mean squared error for the learning data with the test data.\n",
    "\n",
    "6. Plot both actual and predicted values over a \"test\" interval $[-1,+2]$ of 1000 randomly chosen points (instead of the \"learning\" interval $[0, 1]$).  Summarize in one sentence how the goodness of fit changes when more points are added within the learning interval versus when additional points are added outside the learning interval.\n",
    "\n",
    "6.  For $N=1000$, calculate the sum of squared errors, rank, condition number, root mean squared error, correlation coefficient of $\\vec{y}$ and $\\hat{\\vec{y}}$, and r-squared for `degree` = 0, 1, $\\ldots$, 30. Present the results as a dataframe with one row for each value of `degree`. At what degree of the polynomial does the matrix $\\vec{X}$ effectively become singular?\n",
    "\n",
    "Hints: \n",
    "\n",
    "1. To determine whether to print the entire array or only its shape, you might test whether the object is an array (`type(obj) == np.ndarray`) and use `obj.size` to determine whether to print all elements or only the shape.\n",
    "\n",
    "2. Note on interpretation of the results: The columns of $\\vec{X}$ become very highly correlated when the maximum degree of the polynomial exceeds about ten. This is because the function $h(x) = x^{10}$ is well-approximated by a linear combination of $1$, $x^2$, $x^4$, $x^6$, $x^8$. You should also notice that when the maximum degree of the polynomial is small, say 4, the estimated coefficients are somewhat different from the coefficients in the power series expansion of $\\e^x = 1 + x + x^2/2 + x^3/3! + \\ldots$. Intuitively, this is also because the omitted polynomials of higher degree are implicitly being approximated by linear combinations of polynomials of lower degree. The solution to this specific **multicollinearity** problem is to use **orthogonal polynomials**. Specifically, **Chebyshev polynomials** work well for the problem we are considering here. The Python package Scipy has functionality for dealing with different kinds of orthogonal polynomials, inclduing Chebyshev polynomials. Chebyshev polynomials have many applications in finance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: timestamp = '2025-09-02 16:26:19'\n",
      "Execution time = 0.16180690005421638 s\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "tfinish = timeit.default_timer()\n",
    "print(f\"Finished: {timestamp = }\\nExecution time = {tfinish - tstart} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a20250214windows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
